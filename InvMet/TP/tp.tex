\documentclass[11pt,a4paper]{article} 

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[french,english]{babel}

\usepackage{amsthm}
\usepackage{float}
\usepackage{lmodern}%pour un meilleur rendu des polices
\usepackage{verbatim}%du texte non interprt
\usepackage[cmex10]{amsmath}
\usepackage{amssymb}%maths
\usepackage{xspace}
\usepackage[dvipsnames,svgnames,table]{xcolor}
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage{etoolbox}
\usepackage{titlesec}
\usepackage{titletoc}
\usepackage{lastpage}
\usepackage[bookmarks=true,bookmarksnumbered=true]{hyperref}
\usepackage{ctable} % for \specialrule command
\usepackage{cite}
\usepackage{algorithm2e}
\usepackage{alltt}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{mdwtab}
\usepackage{eqparbox}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{dblfloatfix}
\usepackage{url}
\usepackage{tipa}
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{ulem}

%\usepackage{natbib}
%\usepackage[pdftex]{graphicx}
%\usepackage{framed}
%\usepackage[usenames]{color}

\graphicspath{{img/}}
\DeclareGraphicsExtensions{.pdf,.jpeg,.jpg,.png}

%% taille du papier
\textwidth 16 true cm
\textheight 24 true cm
\addtolength{\hoffset}{-1.5cm}
\addtolength{\voffset}{-1.5cm}

%-------- couleurs
\definecolor{grisf}{rgb}{.47,.47,.47} % barre de droite gris fonce
\definecolor{imag}{RGB}{50,0,100}
\definecolor{darkimag}{RGB}{65,15,100}
\definecolor{darkgreen}{RGB}{65,15,100}
\newcommand{\colorc}{\color{darkimag}}
\newcommand{\colorb}{\color{darkimag}}
\newcommand{\colora}{\color{Blue}}

%----------- sections et TOC
% chapitres
\titleformat{\chapter}[display]
  {\normalfont\sffamily\bfseries\huge\colora\centering}{\thechapter}{1ex}
  {{\titlerule[1pt]}\vspace{1.3ex}}[\vspace{1ex}{{\titlerule[1pt]}}]
  
% chapitres etoiles  
\titleformat{name=\chapter,numberless}[display]
  {\normalfont\sffamily\bfseries\LARGE\colora\centering}{}{1ex}
  {{\titlerule[1pt]}\vspace{1.3ex}}[\vspace{1ex}{\titlerule[1pt]}\vspace{2ex}]
  
% sections  
\titleformat{\section}[hang]{\Large\normalfont\sffamily\bfseries\colora}{{\thesection\, }}{0 em}
  {}[{\titlerule[1pt]}\vspace{1ex}]

  
% sous section, sous sous sec, paragraphes  
\titleformat{\subsection}[hang]{\Large\normalfont\sffamily\bfseries\colorc}{{\thesubsection\, }}{0 em}
  {}[{\titlerule}\vspace{.7ex}]
\titleformat{\subsubsection}[hang]{\normalfont\sffamily\bfseries\large}{{\thesubsubsection\, }}{0 em}
  {}[{\color{grisf}\titlerule}\vspace{3pt}]
\titleformat{\paragraph}[runin]{\normalfont\sffamily\bfseries\colorb}{}{0 em}
  {\indent}



%----------------- fancy headers -------------%

\makeatletter
\patchcmd{\@fancyhead}{\rlap}{\color{grisf}\rlap}{}{}
\patchcmd{\headrule}{\hrule}{\color{grisf}\hrule}{}{}
\patchcmd{\@fancyfoot}{\rlap}{\color{grisf}\rlap}{}{}
\patchcmd{\footrule}{\hrule}{\color{grisf}\hrule}{}{}
\makeatother

                                                                    
\fancyhf{}
\fancyhead[R]{\sffamily\colorb{Report}}
\fancyfoot[R]{\sffamily\small\colorb{\thepage/\pageref{LastPage}}}
\fancyhead[L]{\sffamily\small\colorb{Jean-Baptiste Keck}}
\fancyfoot[L]{\sffamily\small\colorb{M2 MSIAM -- Inverse Methods -- 2014-2015}}
\renewcommand{\headrulewidth}{0.2pt} %0.4
\renewcommand{\footrulewidth}{0.2pt} %0
\addtolength{\headheight}{0.pt}

\fancypagestyle{plain}{
  \fancyhead{}
  \renewcommand{\headrulewidth}{0pt}
  }
     
  %-- macros --%   
  \def\hlinewd#1{%
      \noalign{\ifnum0=`}\fi\hrule \@height #1 %
  \futurelet\reserved@a\@xhline} 

  
  
  %------------------- front page ------------------%
  \title{
      \bsc{TP Inverse Methods}
      \vskip 1cm
      {\colorb\textbf{Lorenz Equations}}
      \vskip 1cm
      \colorb\textit{Report}
  }
\author{%
    Jean-Baptiste \bsc{Keck}
    \vskip 0.5cm
    \bsc{M2 Msiam}
}
%\date{27 janvier 2014}
\makeatletter

\def\maketitle{%
    %\thispagestyle{empty}%
    \begin{flushleft}
        \normalfont\LARGE\par
    \end{flushleft}
    \vskip 3cm
    \begin{center}%
        {\colora\specialrule{.2em}{0em}{0em}}
        \vskip 1cm
        {\Huge \@title}%
        \vskip 1cm
        {\colora\specialrule{.2em}{0em}{0em}}
        \vskip 5cm
        {\Huge \@author\par}%
        \vskip 2cm
        {\Huge \@date\par}%
        \vskip 1cm

    \end{center}%
    \clearpage
}

\renewcommand{\ccite}[1]{\textbf{\cite{#1}}}
\renewcommand{\pd}[2]{\dfrac{\partial #1}{\partial #2}}
\renewcommand{\abs}[1]{\left( #1 \right)}
\renewcommand{\norm}[1]{\lVert #1 \rVert}
\renewcommand{\dx}{\ \mathrm{d}x}
\renewcommand{\dt}{\ \mathrm{d}t}
\renewcommand{\u} {\mathbf{u}}
\renewcommand{\k} {\mathbf{k}}
\renewcommand{\v} {\mathbf{v}}
\renewcommand{\w} {\mathbf{w}}
\renewcommand{\h} {\mathbf{h}}
\renewcommand{\f} {\mathbf{f}}
\renewcommand{\g} {\mathbf{g}}
\renewcommand{\uz}{\mathbf{u_0}}
\renewcommand{\ud}{\mathring{\mathbf{u}}}
\renewcommand{\ut}{\tilde{\mathbf{u}}}
\renewcommand{\utrue}{\mathbf{u}^t}}
\renewcommand{\uobs}{\mathbf{u}^{obs}}}
\renewcommand{\xobs}{x^{obs}}}
\renewcommand{\utz}{\tilde{\mathbf{u}}_0}
\renewcommand{\uh}{\hat{\mathbf{u}}}
\renewcommand{\vh}{\hat{\mathbf{v}}}
\renewcommand{\wh}{\hat{\mathbf{w}}}
\renewcommand{\ub}{\bar{\mathbf{u}}}
\renewcommand{\F}{\mathrm{F}}
\renewcommand{\R}{\mathbb{R}}
\renewcommand{\J}{\mathcal{J}}
\renewcommand{\xt}{\tilde{x}}
\renewcommand{\xh}{\hat{x}}
\renewcommand{\yh}{\hat{y}}
\renewcommand{\zh}{\hat{z}}
\renewcommand{\xb}{\bar{x}}

\newcommand{\bigo}[1]{\ensuremath{\mathop{}\mathopen{}O\mathopen{}\left(#1\right)}}
\newcommand{\smallo}[1]{\ensuremath{\mathop{}\mathopen{}o\mathopen{}\left(#1\right)}}

\definecolor{lightgray}{gray}{0.9}
\renewcommand{\colbox}[1]{\colorbox{lightgray}{$ #1 $}}
%%%%%%%

\begin{document}
\pagestyle{fancy}

\maketitle

%\tableofcontents
\clearpage

\section{Theorical work on the continuous model}

\textbf{Lorentz Equations :}
\vskip 0.2cm

$$
\begin{equation} \label{eq:lorentz}
\left \{
\begin{array}{l c l}
    \mathring{x} & = & 10(y - x)\\
    \mathring{y} & = & 28x - y -xz\\
    \mathring{z} & = & xy - \frac{8}{3}z\\
    \multicolumn{3}{l}{x(0) = x_0,\ y(0) = y_0,\ z(0) = z_0}
\end{array}
\right .
\hskip 0.5cm
\Leftrightarrow 
\hskip 0.5cm
\colbox{
\left \{
\begin{array}{l c l}
\ud&=&\f(\u) \\
\u_0&=&[x_0, y_0, z_0]^T
\end{array}
\right .
}
\end{equation}
$$

with $\u(t) = 
\left [
    \begin{array}{c}
        x(t)&
        y(t)&
        z(t)
    \end{array}
\right ]$
and $\f(\u) =
\left [
    \begin{array}{c}
        10(y - x)\\
        28x - y -xz\\
        xy - \frac{8}{3}z\\
    \end{array}
\right ]
$

\vskip 0.5cm
\subsection{Question 1:} 

\vskip 0.3cm
\noindent Let $\J$ be the following cost function :
\vskip 0.3cm

$\colbox{\J(\u_0) = \dfrac{1}{2}\displaystyle \int_0^T\norm{\u(t)-\uobs(t)}^2 \dt}$ where $\u$ is the solution of (1) with initial condition $\u_0$.

\vskip 0.5cm
\noindent Let $T \in \R^*_+,\ \alpha \in \R^*,\ \u_0 \in \R^3,\ \delta\u_0 \in \R^3$
and
$\ut_0 = \u_0 + \alpha\ \delta\u_0$.
\vskip 0.1cm
\noindent Let $\u$ (resp. $\ut$) be the unique solution of the system (\ref{eq:lorentz}) with $\u_0$ (resp. $\ut_0$) as initial condition.
\vskip 0.1cm
\noindent Let $\ub = \dfrac{\ut - \u}{\alpha}$,  $\uh = \lim\limits_{\alpha \to 0} \ub$
}
and assume 
$\mathrm{K} = \left\{t \in\ ]0,T[\ \ |\ \ \norm{\uh(t)} = +\infty \right\}$
is a measure-zero set.
\vskip 0.5cm

$$
\begin{equation} \label{eq:grad}
    \colbox{
        d\left(\J(\u_0)\right)(\delta \u_0) 
        =\nabla \J(\u_0) \cdot \delta\u_0
        = \lim\limits_{\alpha \to 0}\dfrac{\J(\ut_0) - \J(\u_0)}{\alpha}\ 
    }
\end{equation}
$$

$
\mathcal{J}_\alpha
=\dfrac{\J(\utz) - \J(\uz)}{\alpha}
= \dfrac{1}{2\alpha}\displaystyle \int_0^T \left[ \norm{\ut(t) - \uobs(t)}^2 - \norm{\u(t)-\uobs(t)}^2 \right ] \dt
\vskip 0.2cm
\hskip 3.75cm
=\dfrac{1}{2\alpha}\displaystyle \int_0^T \left[ \norm{\u(t) - \uobs(t) + \alpha\ \ub(t)}^2 - \norm{\u(t)-\uobs(t)}^2 \right ] \dt
\vskip 0.2cm
\hskip 3.75cm
=\dfrac{1}{2\alpha}\displaystyle \int_0^T \left[ \alpha^2\ \norm{\ub(t)}^2 + 2 \langle \u(t) - \uobs(t), \alpha\ \ub(t) \rangle\right] \dt
\vskip 0.2cm
\hskip 3.75cm
=\dfrac{1}{2}\displaystyle \int_0^T \left[ \alpha\ \norm{\ub(t)}^2 + 2 \langle \u(t) - \uobs(t), \ub(t) \rangle\right] \dt
\vskip 0.2cm
\hskip 3.75cm
$

$
\Rightarrow
d\left(\J(\u_0)\right)(\delta \u_0) 
= \lim\limits_{\alpha \to 0} \mathcal{J}_\alpha
= \lim \limits_{\alpha \to 0} \dfrac{1}{2}\displaystyle \int_0^T \left[ \alpha\ \norm{\ub(t)}^2 + 2 \langle \u(t) - \uobs(t), \ub(t) \rangle\right] \dt
\vskip 0.2cm
\hskip 3.2cm
= \lim \limits_{\alpha \to 0} 
\left [ \dfrac{1}{2}\displaystyle  \int_{]0,T[ \backslash K} \alpha\ \underbrace{\norm{\ub(t)}^2}_{\leq M} \dt \right ]
+ \displaystyle \int_0^T \langle \u(t) - \uobs(t), \uh(t) \rangle \dt
\vskip 0.2cm
\hskip 3.2cm
= 0 + \displaystyle \int_0^T \langle \u(t) - \uobs(t), \uh(t) \rangle \dt
$

\vskip 0.2cm
$$
\begin{equation} \label{eq:diff}
\colbox{
d\left(\J(\u_0)\right)(\delta \u_0) 
= \displaystyle \int_0^T \left[ \u(t) - \uobs(t) \right]^T \uh(t) \dt
}
\end{equation}
$$

\noindent\textbf{Tangent model :} 

\vskip 0.2cm
$
\widetilde{(1)} - (1) 
\Leftrightarrow
\left \{
\begin{array}{l c l}
    \mathring{\ut} - \mathring{\u} &=&\f(\ut) - \f(\u)\\
    \ut(0) - \u(0)&=&\ut_0 - \u_0
    \right .
\end{array}
\right.
\vskip 0.2cm
\hskip 1.55cm
\Leftrightarrow
\left \{
\begin{array}{l c l}
    \alpha\ \mathring{\ub} &=& \f(\u + \alpha \ub) - \f(\u)\\
    \alpha \ub(0)&=&\alpha\ \delta \u_0
    \right .
}
\end{array}
\right.
\vskip 0.2cm
\hskip 1.55cm
\Rightarrow
\left \{
\begin{array}{l c l c l c l}
    \mathring{\uh} &=&
    \lim\limits_{\alpha \to 0}  \dfrac{\f(\u + \alpha \ub) - \f(\u)}{\alpha}&=&
    d(\f(\u))(\uh) = J_f(\u)\ \uh\\
    \uh(0)&=&\delta \u_0&&
    \right .
}
\end{array}
$

$$
\begin{equation} \label{eq:tangent}
\colbox{
\left \{
\begin{array}{l c l}
    \pd{\uh}{t} &=&J_f(\u)\ \uh\\
    \uh(0)&=&\delta \u_0
    \right .
\end{array}
}
\textrm{ with }
\colbox{
    J_f(\u) = \pd{\f}{\u}(\u) = 
\left [
    \begin{array}{c c c}
        -10&10&0\\
        28-z&-1&-x\\
        y&x&-\frac{8}{3}
    \end{array}
\right ]
}
\end{equation}
$$

\noindent\textbf{Adjoint model :} 
\vskip 0.2cm

Let $\vh :\ ]0,T[\ \to \R^3$ continuously differentiable.

\hskip 0.7cm
$\uh$ may be continuously differentiable because of (4) under stronger assumptions on K 

\hskip 0.7cm
(see 2), $ie$ K$=\varnothing$.

Commodity notations : $\uh \cdot \vh = \langle \uh, \vh \rangle$ and $\uh' = \pd{\uh}{t}$.

\vskip 0.3cm
By integrating the scalar product by part :

$$
\left[ \vh(t) \cdot \uh(t) \right]_0^T
=
\displaystyle \int_0^T \left[
    \vh'(t) \cdot \uh(t)
    + \vh(t) \cdot \uh'(t)
\right] \dt
$$

$$
\Leftrightarrow
\underbrace{\vh(T)}_{\textrm{set to } \vec{0}} \cdot \uh(T)
-  \vh(0) \cdot \underbrace{\uh(0)}_{\delta\uz}
=
\displaystyle \int_0^T \left[
    \vh'(t) \cdot \uh(t)
    + \underbrace{\vh(t) \cdot J_f(\u(t))\uh(t)}_{J_f^*(\u(t)) \vh(t) \cdot \uh(t)}
\right] \dt
$$

$$
\Leftrightarrow
\begin{equation}
\colbox{
    \displaystyle \int_0^T
    \left[
        \vh'(t) + J_f^*(\u(t)) \vh(t)
    \right ]
    \cdot \uh(t)
\right] \dt
=
-  \vh(0) \cdot \delta\uz
 }
\end{equation}
$$

\vskip 0.5cm
Knowing $\u(t)$ and $\uobs(t)\ \forall t\in [0,T]$, and if we take $\vh$ solution of the following adjoint model:

$$
\begin{equation} \label{eq:adjoint}
\hskip 0.5cm
\colbox{
\left \{
\begin{array}{l c l}
    \mathring{\vh}&=&\g(\vh,t) + \h(t)\\
    \vh(T)&=&\vec{0}
\end{array}
\right .
}
\textrm{ with }
\left \{
\begin{array}{l l l l l}
\g(\vh,t)&=&-J_f^*(\u(t))\ \vh(t)&=&-J_f^T(\u(t))\ \vh(t)\\
\h(t)&=&\u(t) - \uobs(t)
\end{array}
\right .
\end{equation}
$$

By (2), (3) and (5) we get directly $\colbox{\nabla \J(\uz) = - \vh(0)}$.





\vskip 0.5cm
\subsection{Question 2:} 
\vskip 0.3cm
\noindent Let now $\J_x$ be the following cost function :
\vskip 0.3cm

$\colbox{\J_x(\u_0) = \dfrac{1}{2}\displaystyle \int_0^T\abs{x(t)-\xobs(t)}^2 \dt}$ where $x$ is the solution of (1) projected on the x-axis with initial condition $\u_0$.

\vskip 0.5cm
With the same notations and assumptions as before on $x$ :

$$
\begin{equation} \label{eq:grad}
    \colbox{
        d\left(\J_x(\u_0)\right)(\delta \u_0) 
        =\nabla \J_x(\u_0) \cdot \delta\u_0
        = \lim\limits_{\alpha \to 0}\dfrac{\J_x(\ut_0) - \J_x(\u_0)}{\alpha}\ 
    }
\end{equation}
$$

$
\mathcal{J}_x^\alpha
=\dfrac{\J(\utz) - \J(\uz)}{\alpha}
= \dfrac{1}{2\alpha}\displaystyle \int_0^T \left[ \abs{\xt(t) - \xobs(t)}^2 - \abs{x(t)-\xobs(t)}^2 \right ] \dt
\vskip 0.2cm
\hskip 3.75cm
=\dfrac{1}{2\alpha}\displaystyle \int_0^T \left[ \abs{x(t) - \xobs(t) + \alpha\ \xb(t)}^2 - \abs{x(t)-\xobs(t)}^2 \right ] \dt
\vskip 0.2cm
\hskip 3.75cm
=\dfrac{1}{2\alpha}\displaystyle \int_0^T \left[ \alpha^2 \xb(t)^2 + 2\alpha\ [x(t) - \xobs(t)]\ \xb(t) \right] \dt
\vskip 0.2cm
\hskip 3.75cm
=\dfrac{1}{2}\displaystyle \int_0^T \left[ \alpha \xb(t)^2 + 2\ [x(t) - \xobs(t)]\ \xb(t) \right] \dt
\vskip 0.2cm
\hskip 3.75cm
$

$
\Rightarrow
d\left(\J_x(\u_0)\right)(\delta \u_0) 
= \lim\limits_{\alpha \to 0} \mathcal{J}_x^\alpha
= \lim \limits_{\alpha \to 0} \dfrac{1}{2}\displaystyle \int_0^T \left[ \alpha\ \xb(t)^2 + 2\ [x(t) - \xobs(t)]\ \xb(t) \right] \dt
\vskip 0.2cm
\hskip 3.2cm
= \lim \limits_{\alpha \to 0} 
\left [ \dfrac{1}{2}\displaystyle  \int_{]0,T[ \backslash K_x} \alpha\ \underbrace{\xb(t)^2}_{\leq M} \dt \right ]
+ \displaystyle \int_0^T [x(t) - \xobs(t)]\ \xh(t) \dt
\vskip 0.2cm
\hskip 3.2cm
= 0 + \displaystyle \int_0^T [x(t) - \xobs(t)]\ \xh(t) \dt
$

\vskip 0.2cm
$$
\begin{equation} \label{eq:diff}
\colbox{
d\left(\J_x(\u_0)\right)(\delta \u_0) 
= \displaystyle \int_0^T [x(t) - \xobs(t)]\ \xh(t) \dt
}
\end{equation}
$$

\noindent\textbf{Tangent model :} 

\vskip 0.2cm
We still have the same tangent model as before (4), and we can project the equations on $x$, $y$ and $z$ to obtain :

$$
\begin{equation} \label{eq:tangent}
    \colbox{
        \left \{
            \begin{array}{l c l}
                \pd{\xh}{t} &=&\pd{f_x}{\u}(\u)\cdot \uh\\
                \\
                \pd{\yh}{t} &=&\pd{f_y}{\u}(\u)\cdot \uh\\
                \\
                \pd{\zh}{t} &=&\pd{f_z}{\u}(\u)\cdot \uh\\
                \\
                \uh(0)&=&\delta \u_0
            \end{array}
        \right .
        \textrm{ with }
        \left\{
                \begin{array}{c c c c l c c c l}
                    \pd{f_x}{\u}(\u)&=&\nabla f_x(\u)&=& [-10 & 10 & 0]^T\\
                    \\
                    \pd{f_y}{\u}(\u)&=&\nabla f_y(\u)&=& [28-z & -1 & -x]^T\\
                    \\
                    \pd{f_z}{\u}(\u)&=&\nabla f_z(\u)&=& [y & x & -\frac{8}{3}]^T\\
                \end{array}
        \right .
    }
\end{equation}
$$

\noindent\textbf{Adjoint model :} 
\vskip 0.2cm

If we take a new function $\wh$ and we integrate the scalar product by part, we still get (5) :

$$
\colbox{
\displaystyle \int_0^T 
\left[ 
    \wh'(t) + J_f^*(\u(t)) \wh(t) 
\right ]
\cdot \uh(t)
\right] \dt
=
-  \wh(0) \cdot \delta\uz
}
$$

\vskip 0.5cm
Knowing $\u(t)$ and $\uobs(t)\ \forall t\in [0,T]$, and if we take $\wh$ solution of the following adjoint model:

$$
\begin{equation} \label{eq:adjoint}
\hskip 0.5cm
\colbox{
\left \{
\begin{array}{l c l}
    \mathring{\wh}&=&\g(\wh,t) + \h^x(t)\\
    \wh(T)&=&\vec{0}
\end{array}
\right .
}
\textrm{ with }
\left \{
\begin{array}{l l l l l}
    \g(\wh,t)&=&-J_f^*(\u(t))\ \wh(t)&=&-J_f^T(\u(t))\ \wh(t)\\
    \h^x(t)&=&\left[ x(t) - \xobs(t), 0, 0 \right]^T
\end{array}
\right .
\end{equation}
$$

The only thing that changed in the adjoint model is the expression of $h(t)$, the new adjoint model does no more take into acount the distance between $y$ and $y^{obs}$ or $z$ and $z^{obs}$.
With this new adjoint model, we still have the same expression for the gradient : $\colbox{\nabla \J_x(\uz) = - \wh(0)}$.


\vskip 0.5cm
\subsection{Question 3:} 
\vskip 0.3cm
\noindent Let finally $\J_2$ be the following cost function :
\vskip 0.3cm

$\colbox{\J_2(\u_0) = \J_b(\u_0) + \J_1(\u_0) 
= \dfrac{1}{2}\norm{\uz - \u^b}^2
+ \displaystyle \int_0^T\norm{\u(t)-\uobs(t)}^2 \dt}$

where $\u$ is the solution of (1) with initial condition $\u_0$ and $\u^b \in \R^3$.

\vskip 0.5cm
\noindent\textbf{Expression of the gradient :} we directly have 
$\colbox{
\nabla \J_2 
= \nabla \J^b + \nabla \J_1
}$
and $\colbox{\nabla \J^b(\uz) = \uz - \u^b}$.
\vskip 0.5cm
\noindent\textbf{Tangent model :} As before nothing changes.
\vskip 0.5cm
\noindent\textbf{Adjoint model :} If $\vh$ is solution of the first adjoint model (6), $\uz - \u^b - \vh(0)$ is the gradient we are looking for because we have seen that $\nabla \J_1(\uz) = -\vh(0)$.

\vskip 0.2cm
\noindent Let $\colbox{\hat{\nu} = \vh + \u^b - \uz}$, we have $\colbox{\mathring{\hat{\nu}} = \mathring{\vh}}$ and $\colbox{-\hat{\nu}(0) = \nabla \J_2(\uz)}$.
\vskip 0.2cm
\noindent As $\g(\vh,t)$ is linear in $\vh$ we can easily get the new adjoint model verified by $\hat{\nu}$ :

$$
\begin{equation} \label{eq:adjoint}
\hskip 0.5cm
\colbox{
\left \{
\begin{array}{l c l}
    \mathring{\hat{\nu}}&=&\g(\hat{\nu},t) + \h^b(t)\\
    \hat{\nu}(T)&=&u^b - u_0
\end{array}
\right .
}
\textrm{ with }
\left \{
\begin{array}{l l l}
    \g(\hat{\nu},t)&=&-J_f^*(\u(t))\ \hat{\nu}(t)=-J_f^T(\u(t))\ \hat{\nu}(t)\\
    \h^b(t)&=& u(t) - \uobs(t) + J_f^*(\u(t))\ \left[ \u^b - \uz \right]
\end{array}
\right .
\end{equation}
$$

The adjoint model now takes into acount the distance between the initial conditions.

\vskip 0.5cm
\subsection{Question 4:} 
\vskip 0.5cm

Let $\Delta_t > 0,\ \ T = N\Delta_t$ and $\u_k = \left[x_k, y_k, z_k\right]^T$ be the state of the system at time $i\Delta_t\ \forall k \in \llbracket 0,N \rrbracket$. The same notations are used for $\u^{obs}$.

As $(1)$ is an hyperbolic system, there is a need for high order algorithms like Runge-Kutta 4 (RK4).

\vskip 0.5cm
\noindent\textbf{Algorithm (RK4):}

$\colbox{\u_0 = \u(0)}$\\
\indent for k from $0$ to $N-1$:\\
\vskip 0.1cm
\hskip 0.5cm
$
\colbox{
\left [
\begin{array}{l l}
    \u_k^0 = \u_k&
    \k_1 = f(\u_k^0)& 
    \u_k^1 = \u_k + \frac{\Delta_t}{2} \k_1&
    \k_2 = f(\u_k^1)& 
    \u_k^2 = \u_k + \frac{\Delta_t}{2} \k_2&
    \k_3 = f(\u_k^2)&
\u_k^3 = \u_k + \Delta_t \k_3&
    \k_4 = f(\u_k^3)&
    \multicolumn{2}{l}{\u_{k+1} = \u_k + \dfrac{\Delta_t}{6}\left[ \k_1 + 2\k_2 + 2\k_3 + \k_4 \right]}&
\end{array}
\right.
}
$

\vskip 0.5cm
\noindent Let $F(\u) : \R^3 \to \R^{3 \times 3}$ such that $\colbox{f(\u) = F(\u)\u}$ and we denote $\colbox{F_k^l = F(\u_k^l)}$.

\vskip 0.3cm
\noindent As $F$ is not unique, we fix it as 
$
\colbox{
F(\u) = 
\left [
    \begin{array}{c c c}
        -10 & 10 & 0 &
        28-\frac{z}{2} & -1 & -\frac{x}{2}& 
        \frac{y}{2} & \frac{x}{2} & -\frac{8}{3}
    \end{array}
\right ]
}
$

\vskip 0.3cm
\noindent With those notations, one step of (RK4) is equivalent to :

\vskip 0.1cm
\hskip 0.5cm
$
\left [
\begin{array}{l l}
    \u_k^0 = \u_k&
    \k_1 = F_k^0 \u_k^0& 
    \u_k^1 = \u_k + \frac{\Delta_t}{2} \k_1&
    \k_2 = F_k^1 \u_k^1& 
    \u_k^2 = \u_k + \frac{\Delta_t}{2} \k_2&
    \k_3 = F_k^2 \u_k^2& 
\u_k^3 = \u_k + \Delta_t} \k_3&
    \k_4 = F_k^3 \u_k^3& 
    \multicolumn{2}{l}{\u_{k+1} = \u_k + \dfrac{\Delta_t}{6}\left[ \k_1 + 2\k_2 + 2\k_3 + \k_4 \right] = [I + \Delta_tA_k]\u_k} = M_k \u_k&
\end{array}
\right.
$

\vskip 0.1cm
\noindent As I failed to expand $A_k$ by hand, I used maple to get the following \sout{nice and compact} expression:
\begin{multline}
A_k = \dfrac{1}{24} \left[ 
    \Delta_t^3\ F_k^3 F_k^2 F_k^1 F_k^0 
    + 2 \Delta_t^2\left( F_k^3 F_k^2 F_k^1 + F_k^2 F_k^1 F_k^0 \right) 
    + 4 \Delta_t^1\left( F_k^3 F_k^2 + F_k^2 F_k^1 + F_k^1 F_k^0 \right)\\
    + 4 \left( F_k^3 + F_k^0 \right) 
    + 8 \left( F_k^2 + F_k^1 \right) 
\right]
\end{multline}

It can be generated with the maple script $model.mw$. Note that with this expression, computing $M_k$ is much more costly than to compute $u_{k+1}$ directly. The matrix coefficients can be computed analyticaly with maple but their expression is way to big to fit nicely in this report.

\vskip 0.3cm
We then have $\colbox{M_k = I + \Delta_t A_k}$ and $\colbox{\u_{k+1} = M_k\u_k}$. I checked this matrix form by comparing it to my initial RK4 code and it gave exactly the same results given the $\Delta_t$ powers are applied after all matrix multiplications.

\vskip 0.5cm
\noident At each step $k$ of this algorithm we take into acount 4 steps of local linearization on $f$ at intermediate points $x_k^l$, so model error should be taken in account. Let $\colbox{Q_k = Q \in \mathscr{S}_3^{++}}$ be some constant model error covariance matrix.

\vskip 0.5cm
\noident $\colbox{\u_k^{obs} = H_k\mathbf{u}^{t}_k + \mathbf{e}_k}$ are our observations, with $H_k$ the observation matrix. At each step we just directly observe the 3D position of the system in original coordinates so there is no additional transformations and $\colbox{H_k = I}$. We observe those positions with a constant observation error covariance matrix $\colbox{R_k = R \in \mathscr{S}_3^{++}}$.

\vskip 0.5cm
\noident Finally let $\colbox{\u^b = \u_0^t + \epsilon}$ be our approximate initial state with associated covariance matrix $\colbox{P^b \in \mathscr{S}_3^{++}}$. 

\vskip 0.5cm
\noindent \textbf{Kalman Filter Algorithm :}
\vskip 0.5cm

\textbf{Initialization}

\colbox{
$
\begin{array}{l l l l}
    & \u^a_0 & = & \u^b &
    & P^a_0  & = & P^b  &
\end{array}
$
}

\vskip 0.5cm

\textbf{Step k (Forecast - Correction)}

\colbox{
$
\begin{array}{l l l l r}
    & \u_{k+1}^f & = & M_k \u_k^a          & (KF1) &
    & P_{k+1}^f  & = & M_k P_k^a M_k^T + Q & (KF2) &
    &            &   &                     &       &
    & K_{k+1}    & = & P_{k+1}^f \left[ P^f_{k+1} + R_{k+1} \right] ^{-1} & (KF3) &
    & \u_{k+1}^a & = & \u_{k+1}^f - K_{k+1} \left[ \u_{k+1}^{obs} - \u_{k+1}^f \right]   & (KF4) &
    & P_{k+1}^a & = & P_{k+1}^f - K_{k+1} P_{k+1}^f   & (KF4) &
\end{array}
$
}

\vskip 0.5cm
\subsection{Question 5:} 
\vskip 0.5cm

The continuous cost function associated with our Kalman filter can be written as:

\vskip 0.5cm
$\colbox{
    \begin{array}{l l l}
        \J_c(\u_0) &=& \J_b(\u_0) + \J_c^1(\u_0)&
                 &=& \dfrac{1}{2} (\uz - \u^b)^TP_b^{-1}(\uz - \u^b)
    + \dfrac{1}{2} \displaystyle \int_0^T [\u(t)-\uobs(t)]^T R(t)^{-1} [\u(t) - \uobs(t)]  \dt&
    \end{array}
}$

where $\u$ is the \textbf{exact continuous solution} of (1) with initial condition $\u_0$.

\vskip 0.5cm

This can be minimized with a gradient descent method, the gradient being computed with the adjoint model or more precisely with corresponding discrete RK4 adjoint code.

\vskip 0.5cm
We can also approximate this cost function by discretizing with our time step $\Delta_t$ to find the variational approach for this inverse problem:

\vskip 0.5cm
$\colbox{
    \begin{array}{l l l}
        \J_d(\u_0) &=& \J_b(\u_0) + \displaystyle \sum_{k=1}^{N}\J_d^k(\u_0)&
        &=& \dfrac{1}{2} (\uz - \u^b)^T P_b^{-1} (\uz - \u^b)
        + \dfrac{\Delta_t}{2} \displaystyle \sum_{k = 1}^N [\u_k-\uobs_k]^T R_k^{-1} [\u_k - \uobs_k]&
    \end{array}
}$

where $\u$ is the \textbf{approximated discrete solution} of (1) using RK4 with initial condition $\u_0$.

\vskip 0.5cm
As $J_d$ is just the sum of strictly convex functions $\J_d^k$, it can be minimized globaly by computing local functional minimization of each $\J_d^k$ using previous obtained optimal value wich is exactly what is done in the Kalman Filter algorithm (each step is a BLUE) but in a time ordered maner for more convenience (discrete model run step by step). Intermediate optimal values have no reason to have something in common with the adjoint method but the \textbf{final value will be the same}.

\vskip 0.5cm
The only problem is that our discrete model is not perfect and introduces errors so this is \textbf{only true} for $\colbox{Q_k = 0\ \forall k}$ or $\colbox{Q = 0}$ in our case. 



\section{Discrete model}
\section{Data assimilation experiments}

\end{document}


